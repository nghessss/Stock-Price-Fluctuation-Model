{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQo0BgOvXrrz"
      },
      "source": [
        "# <center>Stock Price Fluctation</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2ckK7bwXrr4"
      },
      "source": [
        "# Phân tích yêu cầu của công ty\n",
        "## Yêu cầu của công ty\n",
        "Hãy sử dụng dữ liệu được cung cấp trong email này (dữ liệu giá và khối lượng của một vài mã cổ phiếu) để xây dựng một số mô hình dự đoán biến động giá cổ phiếu.\n",
        "**Biến động giá cổ phiếu = Giá cổ phiếu N (phút hoặc giờ hoặc ngày) sau - Giá cổ phiếu hiện tại.**\n",
        "Công ty cung cấp 4 file dữ liệu từ các công ty FPT, MSN, PNJ và VIC bao gồm các trường\n",
        "- Open: Giá mở bán cổ phiếu\n",
        "- High: Giá cao nhất của cổ phiếu trong khoảng thời gian đó.\n",
        "- Low: Giá thấp nhất trong khoảng thời gian đó.\n",
        "- Close: Giá đóng\n",
        "- Volume: Khối lượng giao dịch\n",
        "# Phân tích\n",
        "## Xác định target value\n",
        "$StockPriceFluctuation = Close_{t+1} - Close_{t}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLevLSzKXrr6"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qj_BaAeBXrr8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do55A2MVXrr9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vfjNM1Xrr9"
      },
      "source": [
        "# read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THB6_ZFHXrr-",
        "outputId": "fdfa9919-99dc-4fb6-db7e-8c5cd3248b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Ticker           Date/Time  Open  High   Low  Close  Volume  Open Interest  \\\n",
            "0    FPT 2020-12-22 14:46:00  58.1  58.1  58.1   58.1   11170              0   \n",
            "1    FPT 2020-12-22 14:29:00  58.1  58.1  58.1   58.1    2500              0   \n",
            "2    FPT 2020-12-22 14:26:00  58.2  58.2  58.2   58.2     500              0   \n",
            "3    FPT 2020-12-22 14:25:00  58.2  58.2  58.2   58.2   14820              0   \n",
            "4    FPT 2020-12-22 14:24:00  58.2  58.2  58.2   58.2   27470              0   \n",
            "\n",
            "   StockFluctuation  \n",
            "0               0.0  \n",
            "1              -0.1  \n",
            "2               0.0  \n",
            "3               0.0  \n",
            "4               0.0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 459331 entries, 0 to 459330\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count   Dtype         \n",
            "---  ------            --------------   -----         \n",
            " 0   Ticker            459331 non-null  object        \n",
            " 1   Date/Time         459331 non-null  datetime64[ns]\n",
            " 2   Open              459331 non-null  float64       \n",
            " 3   High              459331 non-null  float64       \n",
            " 4   Low               459331 non-null  float64       \n",
            " 5   Close             459331 non-null  float64       \n",
            " 6   Volume            459331 non-null  int64         \n",
            " 7   Open Interest     459331 non-null  int64         \n",
            " 8   StockFluctuation  459331 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(5), int64(2), object(1)\n",
            "memory usage: 31.5+ MB\n",
            "None\n",
            "Processed data saved to 'processed_stock_data.csv'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def load_and_process_stock_data(file_paths, N):\n",
        "    dataframes = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Ensure the dataframe has the required columns\n",
        "        required_columns = ['Ticker', 'Date/Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Open Interest']\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            print(f\"Warning: {file_path} is missing some required columns. Skipping this file.\")\n",
        "            continue\n",
        "\n",
        "        # Convert Date/Time to datetime\n",
        "        df['Date/Time'] = pd.to_datetime(df['Date/Time'], format='%m/%d/%Y %H:%M')\n",
        "\n",
        "        # Sort by Date/Time in descending order (newest first)\n",
        "        df = df.sort_values('Date/Time', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        # Calculate price fluctuation\n",
        "        df['StockFluctuation'] = df['Close'] - df['Close'].shift(-N)\n",
        "\n",
        "        # Drop rows with NaN values resulting from the shift operation\n",
        "        df = df.dropna()\n",
        "\n",
        "        dataframes.append(df)\n",
        "\n",
        "    # Combine all dataframes\n",
        "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# List of file paths (adjust these to match your actual file paths)\n",
        "file_paths = [\n",
        "    'data/FPT.csv',\n",
        "    'data/MSN.csv',\n",
        "    'data/PNJ.csv',\n",
        "    'data/VIC.csv'\n",
        "]\n",
        "\n",
        "# Set N for the number of periods to look ahead (e.g., 1 for next minute, 5 for 5 minutes ahead, etc.)\n",
        "N = 1\n",
        "\n",
        "# Process the data\n",
        "result_df = load_and_process_stock_data(file_paths, N)\n",
        "\n",
        "# Display the first few rows and info of the resulting dataframe\n",
        "print(result_df.head())\n",
        "print(result_df.info())\n",
        "\n",
        "# Optional: Save the processed data to a new CSV file\n",
        "result_df.to_csv('processed_stock_data.csv', index=False)\n",
        "print(\"Processed data saved to 'processed_stock_data.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhq-5J_iXrr_",
        "outputId": "4e014c5e-4c53-4e7e-d1ce-a2a5e221b177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Statistics by Ticker:\n",
            "              Open    High    Low       Close     Volume StockFluctuation  \\\n",
            "              mean     max    min        mean        sum             mean   \n",
            "Ticker                                                                      \n",
            "FPT      45.071776   58.50  30.22   45.071777  783515270         0.000279   \n",
            "MSN      74.878822  118.00  46.40   74.880772  769290770         0.000072   \n",
            "PNJ      72.182005  100.16  44.04   72.179317  379915372        -0.000006   \n",
            "VIC     105.376528  126.50  68.00  105.378859  322292790         0.000071   \n",
            "\n",
            "                  \n",
            "             std  \n",
            "Ticker            \n",
            "FPT     0.063485  \n",
            "MSN     0.216196  \n",
            "PNJ     0.690948  \n",
            "VIC     0.199338  \n"
          ]
        }
      ],
      "source": [
        "# Optional: Group by Ticker and display summary statistics\n",
        "summary_stats = result_df.groupby('Ticker').agg({\n",
        "    'Open': 'mean',\n",
        "    'High': 'max',\n",
        "    'Low': 'min',\n",
        "    'Close': 'mean',\n",
        "    'Volume': 'sum',\n",
        "    'StockFluctuation': ['mean', 'std']\n",
        "})\n",
        "print(\"\\nSummary Statistics by Ticker:\")\n",
        "print(summary_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5E71psXXrsA"
      },
      "source": [
        "# Data preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgUtbCDrXrsB"
      },
      "source": [
        "## Scaling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1u2GtUdGXrsB"
      },
      "outputs": [],
      "source": [
        "# Initialize scalers for features and target\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "# Define feature columns to scale\n",
        "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "\n",
        "# Apply scaling for each company\n",
        "scaled_dfs = []\n",
        "for ticker, group in result_df.groupby('Ticker'):\n",
        "    # Scale features\n",
        "    group[feature_columns] = feature_scaler.fit_transform(group[feature_columns])\n",
        "    # Scale target (StockFluctuation)\n",
        "    group['StockFluctuation'] = target_scaler.fit_transform(group[['StockFluctuation']])\n",
        "    scaled_dfs.append(group)\n",
        "\n",
        "# Combine back the scaled data\n",
        "scaled_combined_df = pd.concat(scaled_dfs, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZof8QmYXrsC"
      },
      "source": [
        "## Create Time Series Sequences for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OXKLHtPMXrsC"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, feature_columns, target_column, lookback):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[feature_columns].iloc[i:i+lookback].values)\n",
        "        y.append(data[target_column].iloc[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_list, y_list = [], []\n",
        "lookback_period = 30\n",
        "\n",
        "for ticker, group in scaled_combined_df.groupby('Ticker'):\n",
        "    X, y = create_sequences(group, feature_columns, 'StockFluctuation', lookback_period)\n",
        "    X_list.append(X)\n",
        "    y_list.append(y)\n",
        "\n",
        "# Concatenate all the sequences from different companies\n",
        "X_combined = np.concatenate(X_list, axis=0)\n",
        "y_combined = np.concatenate(y_list, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd2uYbgjXrsC"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-9xsEg52XrsD"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzgbgnWZXrsD"
      },
      "source": [
        "# Build LSTM model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuYncF1-XrsD",
        "outputId": "063ca420-8169-4b2d-ecc3-a7b829a0beea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add LSTM layers\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50))\n",
        "\n",
        "# Output layer to predict stock fluctuation\n",
        "model.add(Dense(units=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0jS0rmUFXrsF"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz49cFKHXrsF",
        "outputId": "02eed5a8-c9c7-4805-d20e-41c57b192941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0061\n",
            "Epoch 2/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0067\n",
            "Epoch 3/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0067\n",
            "Epoch 4/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0074\n",
            "Epoch 5/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0080\n",
            "Epoch 6/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0088\n",
            "Epoch 7/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0084\n",
            "Epoch 8/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0099\n",
            "Epoch 9/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0110\n",
            "Epoch 10/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0096\n",
            "Epoch 11/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0093\n",
            "Epoch 12/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0109\n",
            "Epoch 13/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0104\n",
            "Epoch 14/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0099\n",
            "Epoch 16/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0101\n",
            "Epoch 17/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0099\n",
            "Epoch 18/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0105\n",
            "Epoch 19/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0108\n",
            "Epoch 20/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0108\n",
            "Epoch 21/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0122\n",
            "Epoch 22/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0119\n",
            "Epoch 23/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0108\n",
            "Epoch 24/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0135\n",
            "Epoch 25/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0107\n",
            "Epoch 26/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0116\n",
            "Epoch 27/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0120\n",
            "Epoch 28/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0129\n",
            "Epoch 29/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0132\n",
            "Epoch 30/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0125\n",
            "Epoch 31/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0128\n",
            "Epoch 32/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0129\n",
            "Epoch 33/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0082\n",
            "Epoch 34/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0122\n",
            "Epoch 35/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0110\n",
            "Epoch 36/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0128\n",
            "Epoch 37/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0107\n",
            "Epoch 38/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0128\n",
            "Epoch 39/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0135\n",
            "Epoch 40/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0128\n",
            "Epoch 41/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0128\n",
            "Epoch 42/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0125\n",
            "Epoch 43/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0126\n",
            "Epoch 44/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0124\n",
            "Epoch 45/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0128\n",
            "Epoch 46/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0136\n",
            "Epoch 47/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0135\n",
            "Epoch 48/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0124\n",
            "Epoch 49/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0128\n",
            "Epoch 50/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0120\n",
            "Epoch 51/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0126\n",
            "Epoch 52/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0125\n",
            "Epoch 53/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0129\n",
            "Epoch 54/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0129\n",
            "Epoch 55/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0130\n",
            "Epoch 56/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0127\n",
            "Epoch 57/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0127\n",
            "Epoch 58/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0138\n",
            "Epoch 59/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0136\n",
            "Epoch 60/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0134\n",
            "Epoch 61/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0131\n",
            "Epoch 62/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0139\n",
            "Epoch 63/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0144\n",
            "Epoch 64/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0141\n",
            "Epoch 65/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0136\n",
            "Epoch 66/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0141\n",
            "Epoch 67/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0142\n",
            "Epoch 68/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0130\n",
            "Epoch 69/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0125\n",
            "Epoch 70/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0139\n",
            "Epoch 71/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0128\n",
            "Epoch 72/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0147\n",
            "Epoch 73/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0149\n",
            "Epoch 74/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0110\n",
            "Epoch 75/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0140\n",
            "Epoch 76/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0129\n",
            "Epoch 77/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0126\n",
            "Epoch 78/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0153\n",
            "Epoch 79/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0139\n",
            "Epoch 80/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0148\n",
            "Epoch 81/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0127\n",
            "Epoch 82/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0129\n",
            "Epoch 83/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0142\n",
            "Epoch 84/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0156\n",
            "Epoch 85/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0138\n",
            "Epoch 86/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0134\n",
            "Epoch 87/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0135\n",
            "Epoch 88/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0146\n",
            "Epoch 89/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0149\n",
            "Epoch 90/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0138\n",
            "Epoch 91/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0134\n",
            "Epoch 92/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0146\n",
            "Epoch 93/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0132\n",
            "Epoch 94/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0144\n",
            "Epoch 95/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0147\n",
            "Epoch 96/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0139\n",
            "Epoch 97/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0149\n",
            "Epoch 98/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0133\n",
            "Epoch 99/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0133\n",
            "Epoch 100/100\n",
            "\u001b[1m11481/11481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0145\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEsIid7wXrsG",
        "outputId": "3f4fab24-7040-4c0e-ec4c-06ee8023fd63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('keras_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb9VNJsnXrsG"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePjw73B5XrsG",
        "outputId": "87a2bb2e-53e0-401d-e1a3-12d457d6a3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2871/2871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_rescaled = target_scaler.inverse_transform(y_pred)\n",
        "y_test_rescaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 2.2274699621398075\n",
            "Root Mean Squared Error: 1.4924710925642102\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(y_pred_rescaled, y_test_rescaled)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKgGyPU5XrsG"
      },
      "source": [
        "### MAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oROKglPXrsG",
        "outputId": "ab920fcf-f5c5-4395-f5ed-da5b7b8e2907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 1.3556994579401462\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtAKiB70XrsG"
      },
      "source": [
        "### R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlzm0Bm8XrsG",
        "outputId": "8db54b7e-d4b7-40a3-a40e-ed2c9204044a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 score: -55.43829290611654\n"
          ]
        }
      ],
      "source": [
        "r2 = r2_score(y_test_rescaled, y_pred_rescaled)\n",
        "print(\"R2 score:\", r2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
